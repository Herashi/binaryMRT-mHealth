---
title: "small sample correction thingy"
author: "Jieru Shi"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Here is a brief proof of the small sample correction. 

We start from the sandwich estimator:


$$
\begin{align*}
\Sigma_{\theta} &= E \left[ \frac{1}{G} \sum_{j=1}^G \sum_{t=1}^T W_{t,j} h_{t,j}(H_t) h_{t,j}(H_t)^\prime \right]^{-1} \\
                &E \left[ \frac{1}{G} \sum_{j=1}^G \sum_{t=1}^T W_{t,j} \epsilon_{t,j} h_{t,j}(H_t)
                  \times  \frac{1}{G} \sum_{j=1}^G \sum_{t=1}^T W_{t,j} \epsilon_{t,j} h_{t,j}(H_t)^\prime \right] \\
                &E \left[ \frac{1}{G} \sum_{j=1}^G \sum_{t=1}^T W_{t,j} h_{t,j}(H_t) h_{t,j}(H_t)^\prime \right]^{-1}
\end{align*}
$$

We can calculate the bread & meat by **1)** taking averages within every cluster; **2)** taking the expectation across all clusters. Therefore, the terms in the parenthesis should be on a cluster level (what we treat as a unit). 


The robust sandwich covariance estimator for the entire variance matrix is given by:

$$
\frac{1}{M}Q^{-1} \Lambda Q^{-1}
$$

The first term,~$Q$, is given by

$$
\frac{1}{M} \sum_{m=1}^M \frac{1}{G_m}\sum_{j=1}^{G_m} D_{j,m}^T W_{j,m} D_{j,m} 
$$
where $D_{j,m}$ is the model matrix for individual~$j$ in group $g$ associated with
equation~\eqref{eq:directwcls}, and $W_{j,m}$ is a diagonal matrix of individual weights.
The middle term~$\Lambda$ is given by
$$
\frac{1}{M}\sum_{m=1}^M \frac{1}{G_m^2}\sum_{i,j=1}^{G_m} D_{i,m}^\prime W_{i,m} (I_{i,m} - H_{i,m})^{-1}
e_{i,m} e_{j,m}^\prime (I_{j,m} - H_{j,m})^{-1} W_{j,m} D_{j,m}
$$
where $I_i$ is an identity matrix of correct dimension, $e_i$ is the individual-specific residual vector and


$$
H_{j,m} = D_{j,m}
\left( \sum_{m=1}^M\frac{1}{G_m} \sum_{j=1}^{G_m} D_{j,m}^\prime W_{j,m} D_{j,m} \right)^{-1}
D_{j,m}^\prime W_{j,m}
$$
From $Q^{-1} \Lambda Q^{-1}$ we extract $\hat{\Sigma}_{\beta}$.

In the simulation study, we have clusters all with equal size. so the $G_m$ term could go out of the summation. Hence, we have:

$$
\left(\sum_{m=1}^{M}\frac{1}{G_m}\sum_{j=1}^{G_m} D_{j,m}^\prime W_{j,m} D_{j,m} \right)^{-1} = G_m \left( \sum_{m=1}^M \sum_{j=1}^{G_m} D_{j,m}^T W_{j,m} D_{j,m} \right)^{-1}
$$






